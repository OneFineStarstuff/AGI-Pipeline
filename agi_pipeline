{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyP/aesbYbFy6o1/RwTxE2NX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OneFineStarstuff/AGI-Pipeline/blob/main/agi_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import torch\n",
        "import asyncio\n",
        "from typing import List\n",
        "from PIL import Image\n",
        "from fastapi import FastAPI, UploadFile, Depends, HTTPException, Request\n",
        "from fastapi.security import OAuth2PasswordBearer\n",
        "from pydantic import BaseModel\n",
        "import jwt\n",
        "import pyttsx3\n",
        "from loguru import logger\n",
        "import io\n",
        "import uvicorn\n",
        "import signal\n",
        "import sys\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "from ultralytics import YOLO\n",
        "import whisper\n",
        "from functools import lru_cache\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "from fastapi_limiter import FastAPILimiter\n",
        "from fastapi_limiter.depends import RateLimiter\n",
        "import redis.asyncio as redis\n",
        "\n",
        "# === Load Configuration ===\n",
        "with open('config.json', 'r') as f:\n",
        "    config = json.load(f)\n",
        "\n",
        "# === Configuration and Logging Setup ===\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "logger.add(config[\"logging\"][\"log_file\"], rotation=config[\"logging\"][\"rotation\"], level=config[\"logging\"][\"level\"], enqueue=config[\"logging\"][\"enqueue\"], backtrace=config[\"logging\"][\"backtrace\"], diagnose=config[\"logging\"][\"diagnose\"])\n",
        "logger.info(\"Application startup\")\n",
        "\n",
        "# === Security Setup ===\n",
        "SECRET_KEY = os.getenv(\"SECRET_KEY\", config[\"security\"][\"secret_key\"])\n",
        "ALGORITHM = config[\"security\"][\"algorithm\"]\n",
        "oauth2_scheme = OAuth2PasswordBearer(tokenUrl=\"token\")\n",
        "\n",
        "def create_access_token(data: dict):\n",
        "    to_encode = data.copy()\n",
        "    encoded_jwt = jwt.encode(to_encode, SECRET_KEY, algorithm=ALGORITHM)\n",
        "    return encoded_jwt\n",
        "\n",
        "def authenticate_user(token: str = Depends(oauth2_scheme)):\n",
        "    try:\n",
        "        payload = jwt.decode(token, SECRET_KEY, algorithms=[ALGORITHM])\n",
        "    except jwt.PyJWTError:\n",
        "        logger.warning(\"Authentication failed.\")\n",
        "        raise HTTPException(status_code=401, detail=\"Invalid token\")\n",
        "    return payload\n",
        "\n",
        "# === Pydantic Models ===\n",
        "class TextRequest(BaseModel):\n",
        "    text: str\n",
        "\n",
        "class TextResponse(BaseModel):\n",
        "    response: str\n",
        "\n",
        "# === NLP Module (T5 Transformer) ===\n",
        "class NLPModule:\n",
        "    def __init__(self):\n",
        "        model_name = config[\"nlp_model\"][\"model_name\"]\n",
        "        self.tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "        self.model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
        "        logger.info(\"NLP model loaded successfully.\")\n",
        "\n",
        "    @lru_cache(maxsize=100)\n",
        "    def generate_text(self, prompt: str) -> str:\n",
        "        if not prompt.strip():\n",
        "            raise ValueError(\"Prompt cannot be empty.\")\n",
        "        try:\n",
        "            logger.debug(f\"Generating text for prompt: {prompt}\")\n",
        "            inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "            with torch.no_grad():\n",
        "                outputs = self.model.generate(inputs[\"input_ids\"], max_length=100)\n",
        "            response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "            logger.info(f\"Generated response: {response}\")\n",
        "            return response\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error during text generation: {e}\")\n",
        "            raise HTTPException(status_code=500, detail=\"Internal server error during text generation.\")\n",
        "\n",
        "# === CV Module (YOLOv8 for Object Detection) ===\n",
        "class CVModule:\n",
        "    def __init__(self):\n",
        "        model_path = config[\"cv_model\"][\"model_path\"]\n",
        "        self.model = YOLO(model_path).to(device)\n",
        "        logger.info(\"CV model loaded successfully.\")\n",
        "\n",
        "    def detect_objects(self, image: Image.Image) -> str:\n",
        "        if not image:\n",
        "            raise ValueError(\"Image cannot be empty.\")\n",
        "        try:\n",
        "            logger.debug(\"Detecting objects in the image.\")\n",
        "            results = self.model(image)\n",
        "            detections = results.pandas().xyxy[0].to_json()\n",
        "            logger.info(\"Object detection completed successfully.\")\n",
        "            return detections\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error during object detection: {e}\")\n",
        "            raise HTTPException(status_code=500, detail=\"Internal server error during object detection.\")\n",
        "\n",
        "# === Speech Processor (Whisper for Speech-to-Text, PyTTSX3 for Text-to-Speech) ===\n",
        "class SpeechProcessor:\n",
        "    def __init__(self):\n",
        "        whisper_model = config[\"speech_processor\"][\"whisper_model\"]\n",
        "        self.whisper_model = whisper.load_model(whisper_model)\n",
        "        self.tts = pyttsx3.init()\n",
        "        logger.info(\"Speech processor initialized successfully.\")\n",
        "\n",
        "    def speech_to_text(self, audio_file: UploadFile) -> str:\n",
        "        if not audio_file:\n",
        "            raise ValueError(\"Audio file cannot be empty.\")\n",
        "        try:\n",
        "            logger.debug(\"Processing speech-to-text.\")\n",
        "            with audio_file.file as audio_data:\n",
        "                result = self.whisper_model.transcribe(audio_data)\n",
        "            text = result['text']\n",
        "            logger.info(\"Speech-to-text conversion completed successfully.\")\n",
        "            return text\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error during speech-to-text conversion: {e}\")\n",
        "            raise HTTPException(status_code=500, detail=\"Internal server error during speech-to-text conversion.\")\n",
        "\n",
        "    def text_to_speech(self, text: str) -> None:\n",
        "        if not text.strip():\n",
        "            raise ValueError(\"Text cannot be empty.\")\n",
        "        try:\n",
        "            logger.debug(\"Processing text-to-speech.\")\n",
        "            self.tts.say(text)\n",
        "            self.tts.runAndWait()\n",
        "            logger.info(\"Text-to-speech conversion completed successfully.\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error during text-to-speech conversion: {e}\")\n",
        "            raise HTTPException(status_code=500, detail=\"Internal server error during text-to-speech conversion.\")\n",
        "\n",
        "    def __del__(self):\n",
        "        self.tts.stop()\n",
        "\n",
        "# === Enhanced AGI Pipeline ===\n",
        "class EnhancedAGIPipeline:\n",
        "    def __init__(self):\n",
        "        self.nlp = NLPModule()\n",
        "        self.cv = CVModule()\n",
        "        self.speech_processor = SpeechProcessor()\n",
        "\n",
        "    async def process_nlp(self, text: str) -> str:\n",
        "        return await asyncio.to_thread(self.nlp.generate_text, text)\n",
        "\n",
        "    async def process_cv(self, image: Image.Image) -> str:\n",
        "        return await asyncio.to_thread(self.cv.detect_objects, image)\n",
        "\n",
        "    async def process_speech_to_text(self, audio_file: UploadFile) -> str:\n",
        "        return await asyncio.to_thread(self.speech_processor.speech_to_text, audio_file)\n",
        "\n",
        "    async def process_text_to_speech(self, text: str) -> None:\n",
        "        await asyncio.to_thread(self.speech_processor.text_to_speech, text)\n",
        "\n",
        "# === FastAPI Application ===\n",
        "app = FastAPI()\n",
        "\n",
        "# CORS Middleware\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=[\"*\"],\n",
        "    allow_credentials=True,\n",
        "    allow_methods=[\"*\"],\n",
        "    allow_headers=[\"*\"],\n",
        ")\n",
        "\n",
        "# Redis for Rate Limiting\n",
        "redis_client = redis.from_url(\"redis://localhost\")\n",
        "FastAPILimiter.init(redis_client)\n",
        "\n",
        "pipeline = EnhancedAGIPipeline()\n",
        "\n",
        "# === Graceful Shutdown ===\n",
        "def shutdown_signal_handler(sig, frame):\n",
        "    print('Shutting down gracefully...')\n",
        "    sys.exit(0)\n",
        "\n",
        "signal.signal(signal.SIGINT, shutdown_signal_handler)\n",
        "signal.signal(signal.SIGTERM, shutdown_signal_handler)\n",
        "\n",
        "# === Endpoints ===\n",
        "@app.post(\"/process-nlp/\", response_model=TextResponse, dependencies=[Depends(authenticate_user), Depends(RateLimiter(times=10, seconds=60))])\n",
        "async def process_nlp(request: TextRequest):\n",
        "    response = await pipeline.process_nlp(request.text)\n",
        "    return {\"response\": response}\n",
        "\n",
        "@app.post(\"/process-cv-detection/\", dependencies=[Depends(authenticate_user), Depends(RateLimiter(times=5, seconds=60))])\n",
        "async def process_cv_detection(file: UploadFile):\n",
        "    image = Image.open(io.BytesIO(await file.read()))\n",
        "    response = await pipeline.process_cv(image)\n",
        "    return {\"detections\": response}\n",
        "\n",
        "@app.post(\"/batch-cv-detection/\", dependencies=[Depends(authenticate_user), Depends(RateLimiter(times=3, seconds=60))])\n",
        "async def batch_cv_detection(files: List[UploadFile]):\n",
        "    tasks = [pipeline.process_cv(Image.open(io.BytesIO(await file.read()))) for file in files]\n",
        "    responses = await asyncio.gather(*tasks)\n",
        "    return {\"batch_detections\": responses}\n",
        "\n",
        "@app.post(\"/speech-to-text/\", response_model=TextResponse, dependencies=[Depends(authenticate_user), Depends(RateLimiter(times=10, seconds=60))])\n",
        "async def speech_to_text(file: UploadFile):\n",
        "    response = await pipeline.process_speech_to_text(file)\n",
        "    return {\"response\": response}\n",
        "\n",
        "@app.post(\"/text-to-speech/\", dependencies=[Depends(authenticate_user), Depends(RateLimiter(times=10, seconds=60))])\n",
        "async def text_to_speech(request: TextRequest):\n",
        "    await pipeline.process_text_to_speech(request.text)\n",
        "    return {\"response\": \"Speech synthesis complete.\"}\n",
        "\n",
        "# === Run the Application ===\n",
        "if __name__ == \"__main__\":\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)"
      ],
      "metadata": {
        "id": "6I6J0an3Z-1t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
